# ğŸ¤Ÿ Voice2Sign â€“ Indian Sign Language Communication Tool

### ğŸŒ Bridging the communication gap between Deaf and Non-Speaking Individuals

Voice2Sign is an AI-powered prototype that converts **text â†” sign language gestures** using **computer vision** and **deep learning**.  
The goal is to make real-time communication easier for individuals using Indian Sign Language (ISL).

---

## ğŸš€ Features

### ğŸ–ï¸ ISL to Text
- Detects **two-handed ISL gestures** using your webcam  
- Processes live video feed via **MediaPipe** hand tracking  
- Predicts the corresponding alphabet or word using a **CNN model** trained on custom ISL gesture datasets

### ğŸ”¤ Text to ISL
- Converts typed text (Aâ€“Z) into sign visuals  
- Displays pre-stored ISL alphabet images dynamically in a Streamlit UI  

### ğŸ§  Machine Learning
- Custom CNN trained with real ISL gestures  
- Supports grayscale gesture recognition at 128Ã—128 resolution  
- Augmented dataset for better generalization  

---

## ğŸ§© Tech Stack

| Category | Tools / Libraries |
|-----------|-------------------|
| **Frontend (UI)** | [Streamlit](https://streamlit.io/) |
| **Computer Vision** | [OpenCV](https://opencv.org/), [MediaPipe](https://developers.google.com/mediapipe) |
| **Deep Learning** | [TensorFlow](https://www.tensorflow.org/), [Keras](https://keras.io/) |
| **Data Augmentation** | ImageDataGenerator |
| **Model Training** | Custom CNN with 3 Conv Layers, BatchNorm, Dropout |
| **Language** | Python 3.12 |

---

## âš™ï¸ Setup Instructions

### ğŸ§± Step 1 â€” Clone the Repository
```bash
git clone https://github.com/CodeWithYuva/Voice2sign.git
cd Voice2sign
ğŸ§° Step 2 â€” Create Virtual Environment
bash
Copy code
python -m venv env
env\Scripts\activate
ğŸ§© Step 3 â€” Install Dependencies
bash
Copy code
pip install -r requirements.txt
ğŸ¯ Step 4 â€” Run the App
bash
Copy code
streamlit run app.py
ğŸ§  Training Your Own Model
Collect gestures using:

bash
Copy code
python data_collection.py
Preprocess and augment images:

bash
Copy code
python preprocessing.py
Train the CNN:

bash
Copy code
python train_model.py
Run live prediction (works standalone):

bash
Copy code
python live_prediction.py
ğŸ“‚ Project Structure
graphql
Copy code
Voice2sign/
â”œâ”€â”€ app.py                     # Streamlit UI
â”œâ”€â”€ live_prediction.py         # Real-time ISL â†’ Text prediction
â”œâ”€â”€ data_collection.py         # Collect custom gesture dataset
â”œâ”€â”€ preprocessing.py           # Preprocessing & data augmentation
â”œâ”€â”€ train_model.py             # CNN model training
â”œâ”€â”€ best_model.h5              # Saved trained model
â”œâ”€â”€ class_names.txt            # Class label mapping
â”œâ”€â”€ signs/                     # Stored ISL alphabet images (Aâ€“Z)
â”œâ”€â”€ dataset/                   # Raw gesture captures
â”œâ”€â”€ processed_dataset/         # Preprocessed .npy images
â”œâ”€â”€ requirements.txt           # Dependencies
â””â”€â”€ README.md                  # Documentation
ğŸ’¡ Future Improvements
ğŸ” Add real-time voice â†” sign translation

ğŸ—£ï¸ Integrate speech recognition (Google Speech API)

ğŸ§ Add gesture-to-speech output using text-to-speech

ğŸŒ Host as a web application for accessibility

ğŸ‘¨â€ğŸ’» Author
Yuvaraj
ğŸ“ Developer passionate about accessibility, AI, and assistive communication systems.
ğŸ“§ [Add your email or LinkedIn here]

ğŸªª License
This project is licensed under the MIT License â€” see the LICENSE file for details.
